{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7d96e1",
   "metadata": {},
   "source": [
    "# Lesson 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e83c5",
   "metadata": {},
   "source": [
    "## Step 1: Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85123f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.539189Z",
     "start_time": "2022-09-17T13:21:31.527804Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9cec2",
   "metadata": {},
   "source": [
    "### DATASETS & DATALOADERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9187d",
   "metadata": {},
   "source": [
    "Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "More info: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2880d594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.568399Z",
     "start_time": "2022-09-17T13:21:31.542367Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.2):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a84552f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.584393Z",
     "start_time": "2022-09-17T13:21:31.572394Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train,batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test,batch_size=32, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d41e87",
   "metadata": {},
   "source": [
    "## Step 2: Prepearing module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a7e60e",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd633c",
   "metadata": {},
   "source": [
    "Pytorch uses modules to represent neural networks: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "Xavier and kaiming weight initialization: https://pytorch.org/docs/stable/nn.init.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1582b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.611817Z",
     "start_time": "2022-09-17T13:21:31.584393Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 2)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Softmax(dim = 1)\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7459a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.628373Z",
     "start_time": "2022-09-17T13:21:31.611817Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001)\n",
    "    # enumerate epochs\n",
    "    for epoch in tqdm_notebook(range(500)):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6d828d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.646233Z",
     "start_time": "2022-09-17T13:21:31.632408Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        # convert to class labels\n",
    "        yhat = np.argmax(yhat, axis=1)\n",
    "        # reshape for stacking\n",
    "        actual = actual.reshape(-1, 1)\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c878eabb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.660297Z",
     "start_time": "2022-09-17T13:21:31.646719Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "path = 'model_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caaf7f76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.714371Z",
     "start_time": "2022-09-17T13:21:31.661718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256 1064\n"
     ]
    }
   ],
   "source": [
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aaf04c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.743427Z",
     "start_time": "2022-09-17T13:21:31.719939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1eb31d74fa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9001cfff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.759660Z",
     "start_time": "2022-09-17T13:21:31.747592Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the netw\n",
    "model = MLP(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ec495e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:21:31.778781Z",
     "start_time": "2022-09-17T13:21:31.764619Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden1): Linear(in_features=12, out_features=10, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (hidden2): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (hidden3): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (act3): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d82326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:26:39.994619Z",
     "start_time": "2022-09-17T13:21:31.781686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2363530c58412f85b661b4077816b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09f1cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-17T13:26:40.500882Z",
     "start_time": "2022-09-17T13:26:39.998820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f1213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ff650a",
   "metadata": {},
   "source": [
    "# Example on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71c970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/digit-recognizer'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55221c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "test_df = pd.read_csv(\"digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5265af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape , test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "132ee90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d032aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_name, img_dir, transform=None, target_transform=None , label_name = \"label\"):\n",
    "        \n",
    "        self.img_filename = csv_name\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label_name = label_name\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, self.img_filename)\n",
    "        self.img_df = pd.read_csv(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Extracting all the other columns except label_name\n",
    "        img_cols = [ i for i in self.img_df.columns if i not in self.label_name]\n",
    "        \n",
    "        image = self.img_df.iloc[[idx]][img_cols].values\n",
    "\n",
    "        # Reshaping the array from 1*784 to 28*28\n",
    "        image = image.reshape(28,28)\n",
    "        # image = image.astype(float)\n",
    "\n",
    "        # Scaling the image so that the values only range between 0 and 1\n",
    "        image = image/255.0\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        image = image.to(torch.float)    \n",
    "        \n",
    "        if self.label_name in self.img_df.columns:\n",
    "            \n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            label = int(self.img_df.iloc[[idx]][self.label_name].values)\n",
    "            return image, label\n",
    "        \n",
    "        # Exceptions for test where labels are absent\n",
    "        else :\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa57b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target values in training dataset ; \n",
      "0    0.098386\n",
      "1    0.111534\n",
      "2    0.099444\n",
      "3    0.103598\n",
      "4    0.096958\n",
      "5    0.090344\n",
      "6    0.098492\n",
      "7    0.104788\n",
      "8    0.096746\n",
      "9    0.099709\n",
      "Name: label, dtype: float64\n",
      "Distribution of target values in validation dataset ; \n",
      "0    0.098333\n",
      "1    0.111429\n",
      "2    0.099524\n",
      "3    0.103571\n",
      "4    0.096905\n",
      "5    0.090476\n",
      "6    0.098571\n",
      "7    0.104762\n",
      "8    0.096667\n",
      "9    0.099762\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(train_df)))\n",
    "train_indices , test_indices = train_test_split(indices, test_size=0.1, stratify=train_df['label'])\n",
    "\n",
    "len(train_indices) , len(test_indices) , len(train_df)\n",
    "\n",
    "train_subset = train_df.loc[train_indices]\n",
    "val_subset = train_df.loc[test_indices]\n",
    "\n",
    "print(\"Distribution of target values in training dataset ; \")\n",
    "print( train_subset['label'].value_counts().sort_index() / train_subset['label'].value_counts().sort_index().sum() )\n",
    "\n",
    "print(\"Distribution of target values in validation dataset ; \")\n",
    "print( val_subset['label'].value_counts().sort_index() / val_subset['label'].value_counts().sort_index().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9822d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 1\n"
     ]
    }
   ],
   "source": [
    "# Crerating a temp dataset\n",
    "train_csv_name = \"train.csv\"\n",
    "test_csv_name = \"test.csv\"\n",
    "img_dir = \"digit-recognizer/\"\n",
    "\n",
    "# Converting X variables to Tensors\n",
    "transforms = transforms.Compose( [transforms.ToTensor() , transforms.Normalize((0.5,), (0.5,)) , ] )\n",
    "\n",
    "# Converting y-labels to one hot encoding\n",
    "# target_transform = Lambda(lambda y: torch.zeros(\n",
    "#     len(train_df['label'].unique()), dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "# This is not need since we are going to be using cross entropy loss function\n",
    "\n",
    "label_name = \"label\"\n",
    "\n",
    "train_dataset = CustomMNISTDataset(csv_name = train_csv_name , img_dir = img_dir,\n",
    "                                   transform = transforms , target_transform = None , label_name = label_name)\n",
    "\n",
    "# Inspecting the fist line item under dataset\n",
    "x0 , y0 = train_dataset[0]\n",
    "print(x0.shape , y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21968f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5,), std=(0.5,))\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ddae7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "figure.add_subplot(rows, cols, 1)\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    sample_img , sample_lbl = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(sample_lbl)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(sample_img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe63a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "x0 True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "torch.cuda.is_available()\n",
    "x0 = x0.to(device)\n",
    "print(\"x0\" , x0.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e918eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(train_df)))\n",
    "train_indices , valid_indices = train_test_split(indices, test_size=0.1, stratify=train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a951a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "648f8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset , batch_size=1024, sampler=train_sampler, num_workers=16)\n",
    "valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, sampler=valid_sampler, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42de64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 , y0 = next(iter(train_dataloader))\n",
    "# x0.shape , y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f565179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00306f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97f08be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_MODEL(Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_MODEL, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            Linear(784, 128),\n",
    "            ReLU(),\n",
    "            Linear(128, 64),\n",
    "            ReLU(),\n",
    "            Linear(64, 10)\n",
    "            ## Softmax layer ignored since the loss function defined is nn.CrossEntropy()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return  logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee0d6658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_MODEL(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_MODEL().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e90b80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "807b1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7804d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    # Total size of dataset for reference\n",
    "    size = 0\n",
    "    \n",
    "    # places your model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    # loss batch\n",
    "    batch_loss = {}\n",
    "    batch_accuracy = {}\n",
    "    \n",
    "    correct = 0\n",
    "    _correct = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Gives X , y for each batch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Converting device to cuda\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Compute prediction error / loss\n",
    "        # 1. Compute y_pred \n",
    "        # 2. Compute loss between y and y_pred using selectd loss function\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Backpropagation on optimizing for loss\n",
    "        # 1. Sets gradients as 0 \n",
    "        # 2. Compute the gradients using back_prop\n",
    "        # 3. update the parameters using the gradients from step 2\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _correct = (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        _batch_size = len(X)\n",
    "        \n",
    "        correct += _correct\n",
    "        \n",
    "        # Updating loss_batch and batch_accuracy\n",
    "        batch_loss[batch] = loss.item()\n",
    "        batch_accuracy[batch] = _correct/_batch_size\n",
    "        \n",
    "        size += _batch_size\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}]\")\n",
    "    \n",
    "    correct/=size\n",
    "    print(f\"Train Accuracy: {(100*correct):>0.1f}%\")\n",
    "    \n",
    "    return batch_loss , batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69fa4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, model, loss_fn):\n",
    "    \n",
    "    # Total size of dataset for reference\n",
    "    size = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Setting the model under evaluation mode.\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    _correct = 0\n",
    "    _batch_size = 0\n",
    "    \n",
    "    batch_loss = {}\n",
    "    batch_accuracy = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Gives X , y for each batch\n",
    "        for batch , (X, y) in enumerate(dataloader):\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            model.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            batch_loss[batch] = loss_fn(pred, y).item()\n",
    "            test_loss += batch_loss[batch]\n",
    "            _batch_size = len(X)\n",
    "            \n",
    "            _correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            correct += _correct\n",
    "            \n",
    "            size+=_batch_size\n",
    "            batch_accuracy[batch] = _correct/_batch_size\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    ## Calculating loss based on loss function defined\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    ## Calculating Accuracy based on how many y match with y_pred\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"Valid Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return batch_loss , batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95aacf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_loss = []\n",
    "train_batch_accuracy = []\n",
    "valid_batch_accuracy = []\n",
    "valid_batch_loss = []\n",
    "train_epoch_no = []\n",
    "valid_epoch_no = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d72e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    _train_batch_loss , _train_batch_accuracy = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    _valid_batch_loss , _valid_batch_accuracy = validation(valid_dataloader, model, loss_fn)\n",
    "    for i in tqdm_notebook(range(len(_train_batch_loss)), desc = \"Train\"):\n",
    "        train_batch_loss.append(_train_batch_loss[i])\n",
    "        train_batch_accuracy.append(_train_batch_accuracy[i])\n",
    "        train_epoch_no.append( t + float((i+1)/len(_train_batch_loss)))     \n",
    "    for i in tqdm_notebook(range(len(_valid_batch_loss)), desc = \"Validation\"):\n",
    "        valid_batch_loss.append(_valid_batch_loss[i])\n",
    "        valid_batch_accuracy.append(_valid_batch_accuracy[i])\n",
    "        valid_epoch_no.append( t + float((i+1)/len(_valid_batch_loss)))     \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8971208",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 16))\n",
    "\n",
    "\n",
    "figure.add_subplot(2, 2, 1)\n",
    "plt.plot(train_epoch_no , train_batch_accuracy)\n",
    "plt.title(\"Train Batch Accuracy\")\n",
    "plt.xlabel(\"Epochs\") \n",
    "plt.ylabel(\"Train Accuracy\") \n",
    "\n",
    "figure.add_subplot(2, 2, 2)\n",
    "plt.plot(train_epoch_no , train_batch_loss)\n",
    "plt.title(\"Train Batch Loss\")\n",
    "plt.xlabel(\"Epochs\") \n",
    "plt.ylabel(\"Train Loss\") \n",
    "\n",
    "figure.add_subplot(2, 2, 3)\n",
    "plt.plot(valid_epoch_no , valid_batch_accuracy)\n",
    "plt.title(\"Valid Batch Accuracy\")\n",
    "plt.xlabel(\"Epochs\") \n",
    "plt.ylabel(\"Train Accuracy\") \n",
    "\n",
    "figure.add_subplot(2, 2, 4)\n",
    "plt.plot(valid_epoch_no , valid_batch_loss)\n",
    "plt.title(\"Valid Batch Loss\")\n",
    "plt.xlabel(\"Epochs\") \n",
    "plt.ylabel(\"Train Loss\") \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321466aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
